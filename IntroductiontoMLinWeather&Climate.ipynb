{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b9e7f39-81fc-4b76-ab53-32e810c2916b",
   "metadata": {},
   "source": [
    "# MOOC on  ML in Weather & Climate\n",
    "by ECMWF and iFAB (2023)\n",
    "\n",
    "## Speech of Rabier\n",
    "\n",
    "- Florence Rabier is the director general of ECMWF\n",
    "- created in 1975 to push the limits of weather prediction\n",
    "- they support 35 countries. 23 member states and 12\n",
    "\n",
    "In numerical weather prediction we have:\n",
    " - model\n",
    " - observations\n",
    " - supercomputer\n",
    "\n",
    "1. Observations\n",
    "2. data assimilation: combining observations with the model\n",
    "3. forecast models\n",
    "4. post processing\n",
    "\n",
    "Right now we have a full Earth system (sea, atmosphere, ice, ...)\n",
    "More than 95% of the observations come from satellites (rest of ballons, aircrafts, etc)\n",
    "\n",
    "- They run ensambles of 50-100 simulations. \n",
    "- 700 PBytes of data\n",
    "- huge societal impact (transport, agriculture, solar, wind energies, etc)\n",
    "\n",
    "- flood forecasting\n",
    "- forecasting atmospheric composition\n",
    "- climate monitoring\n",
    "- polen in the air\n",
    "- pollution\n",
    "\n",
    "ECMWF manages lately 2 copernicus services:\n",
    "- Climate Change Servcie\n",
    "- Atmosphere Monitoring Service\n",
    "\n",
    "Data assimilation is used in order to introduce the initial conditions to the NWP models (or ML models). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05332f6-9991-4d1e-bb0c-517d61c446a3",
   "metadata": {},
   "source": [
    "## Speech of Francesco Ubertini\n",
    "- president of iFAB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c28b78-4cd7-4bf5-83e9-237c4750ae8d",
   "metadata": {},
   "source": [
    "## Experts' opinions on Machine Learning\n",
    "- why machine learning?\n",
    "  - detecting outliers\n",
    "  - non-linear partial differential equations for describing the evolution of atmospheric states. -> ML to increase the accuracy of the forecast\n",
    "  - versatility. lack of obervations in some areas. Update model with reinforcement model. Xplainable AI to substract underlying unidentified patterns. Near-real time flood detection. Accesibility.\n",
    "  - does things cheaper/ faster. can speed up parts of NWP. Makes things better. Extract new relationships, to learn new science about the climate system. \n",
    "  - new ways to characterize errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7944052f-c3d7-47be-84df-0ec11861c9b6",
   "metadata": {},
   "source": [
    "## What is ML and what types are there?\n",
    "by Dr. Dramsch\n",
    "\n",
    "- supervised\n",
    "- unsupervised - dimensionality reduction\n",
    "- semi supervised (partially label data set, label propagation). cloud detection\n",
    "- reinforcement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd48b0fe-d093-4fda-84a0-84d9a95b3159",
   "metadata": {},
   "source": [
    "## Why should we consider ML for weather and climate modelling?\n",
    "by Peter Dueben\n",
    "- Earth is huge. 10 km resolution is the state-of-the-art\n",
    "- emulating model components\n",
    "- data compression\n",
    "- optimize HPC and data workflow\n",
    "- uncertainties\n",
    "\n",
    "exponential increase in data volumne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f63deb-77c5-4594-bc39-23c6b6d58011",
   "metadata": {},
   "source": [
    "## Challenges for ML in W&C Modelling\n",
    "by Jesper Dramsch\n",
    "\n",
    "- very heterogeneous data sources from satellites, aircrafts, ships, etc. ML needs of a structured data set\n",
    "- NWP codes are in Fortran. ML in Python. Communication.\n",
    "  \n",
    "- ML is here to stay.\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046cee0c-d920-4c21-b5d6-ea5a4147d3ce",
   "metadata": {},
   "source": [
    "# Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac972f2-4317-4f88-9780-24a6008363af",
   "metadata": {},
   "source": [
    "## Observations in NWP\n",
    "\n",
    "- WE need to develop a physical model of the measurement process. Data assimilaton\n",
    "- Microwave and infrawave satellites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea86512-384a-4f06-a0a5-8cd256872382",
   "metadata": {},
   "source": [
    "## Sensors by Mark HIggins EUMETSAT\n",
    "\n",
    "- Satellite METOP. Humidity, temperatures, water at land surface, ocean surface, etc. That info gets into the computer models. THat is known as data assimilation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b379b7c1-3766-4bcf-a220-6e70b502fe94",
   "metadata": {},
   "source": [
    "## ML for the processing of spatial data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9286258d-55b3-4671-b7da-8296a03f410f",
   "metadata": {},
   "source": [
    "# Computing\n",
    "- Christine Kitchen is the deputy office of ECMWF HPC? In Bologna, Italy\n",
    "- ECMWF data center and HPC in Bologna\n",
    "  - antisismic boxes (storage and computing, 2x2 (duplicated each)) for the data and hpc\n",
    "  - MARS: meteorogical archival and retrieval system\n",
    "  - since 2021 they are installing all the elements and run the operational system. Started in 2018 the constrcution.\n",
    "\n",
    "## The synergies between machine learning and high-performance computing\n",
    "\n",
    "- ML can help to reduce the computing\n",
    "  - Conventional uses complex algorithms, with lots of physics, etc\n",
    "  - numerical operations and data structure are\n",
    "  - deep learning tools can be done with dense linear algebra. Many operations per data units. Moder hardware (GPUs) can be used for efficiently. A deep learning tool can often work at much lower numerical precision (less than 32, 64 bits)\n",
    "  - progress in AI is based on the use of supercomputers. Many money for hardware for AI.\n",
    "  - lots of software to make quick progress with minimal effort/knowledge (pytorch, tensorflow)\n",
    "  - ML tools need a lot of power only during training.\n",
    "\n",
    "## Machine Learning with HPC\n",
    "- GPU is nice for matrix multiplication\n",
    "- Accelerators for Deep Learning\n",
    "  - Tensor Processing UNit TPU\n",
    "  - Graphcore\n",
    "  - SambaNova\n",
    "  - CerebrasWSE\n",
    "- Fat-tree topology\n",
    "## Cloud computing and European Weather Cloud\n",
    "- Infrastructure as a Service (IaaS)\n",
    "- Openstack is a free open standard cloud computing platform, mostly deployed as IaaS for public and private cloud deployments, where virtual servers and other resources are made available to users. The software platform consists of interrelated components that control diverse, multi-vendor hardware pools of processing, storage, and networking resources throughout a datacentre. Users can manage their resources through a web-based dashboard, command-line tools, or through RESTful web services. So key features are: Compute, Storage, and Networking\n",
    "- Kubernetes or K8s is an open-source container-orchestration system for automating computer application deployment, scaling, and management. Many cloud services offer a Kubernetes-based platform or IaaS (PaaS or IaaS like Openstack) on which K8 can be deployed as a platform-providing service. So key features are: Lightweight, built for any deployment (private, public, hybrid cloud and highly modular).\n",
    "\n",
    "Most K8s deployments thus far have been on top Platforms that control the lifecycle of virtual machines like Openstack or VMWARE.\n",
    "\n",
    "\n",
    "This deployment is designed to isolate Kubernetes environments sharing the same infrastructure and because many IT organizations lacked the tools and/or expertise required to manage Kubernetes natively. It was/is easier to simply extend existing tools to manage Kubernetes as an extension of a virtual machine-based platform (IaaS). However, more recently organizations become more familiar with native Kubernetes toolsets and alternative approaches to isolating workloads and therefore some lighter-weight virtual machines technologies emerge.(e.g., Mirantis have begun rolling out highly distributed services based on Kubernetes that make no use of OpenStack at all.)\n",
    "\n",
    "- Dr Vasileios Baousis\n",
    "  - cloud and edge computing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3992f666-f8c5-4876-899b-42f6c84756f1",
   "metadata": {},
   "source": [
    "# Forecast model\n",
    "\n",
    "## concept and state of the art by Peter Dueben\n",
    "\n",
    "- 5 ingredients\n",
    "  - equations that describe the motion of the particles. We know the equations, however we cannot solve them analyticcally.\n",
    "  - We need to define in grid-points (discontinuos). Then we can solve the equation of motion numerically.\n",
    "  - But lots of work needs to be done for DISCREATIZATION. Define how the grid points interact with each other. Takes more than 10 years to construct a new model.\n",
    "  - we need supercomputers.\n",
    "  - sub-grid-scale parametrisation schemes are needed in order to calculate small things in the grid. like clouds.\n",
    "\n",
    "One of the pioneers of numerical weahter forecasts was Lewis Fry Richardson. \n",
    "\n",
    "## Forecasting with ML by Matthew Chantry\n",
    "\n",
    "- We can use it for acceleration\n",
    "  - machine learning emulator of an expensive component. Like the parametrization of observables in small grid. It is GPU friendly. \n",
    "- for model improvement:\n",
    "  - Learn new elements, like a new convection scheme. also to correct model drift.\n",
    "- there are models that are fully ML, like WeahterBench. So far results for nowcasting, not for 10 days.\n",
    "\n",
    "## WeatherBench by Mariana Clare\n",
    "- she uses ML to quantify uncertainty\n",
    "- The ground truth data comes from ERA5, a reanalysis dataset produced by ECMWF. Reanalysis datasets are model simulations that are kept close to observations and therefore represent a best guess of the state of the atmosphere at any point in time and space. Around 40 years of data are available. Raw ERA5 data comes at a resolution of 0.25 degrees, approximately 30 km. For many machine learning applications, these data volumes are too large. Therefore, WeatherBench also provides data that is regridded on to coarser resolutions. The coarsest resolution is 5.625 degrees, which is also the resolution at which the goal metrics for this dataset are evaluated.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402ebfe8-c6ce-468b-a706-89407eafbb10",
   "metadata": {},
   "source": [
    "# Data assimilation\n",
    "\n",
    "## INtroduction by Massimo Bonavita\n",
    "- model forecast + observations --> analysis with smaller errors. The combination of them is now as data assimilation.\n",
    "- 4D (space + time) variational data assimilation. FInds new trajectory of the model consisten with the observations but not too far from the initial conditions.\n",
    "- ensemble (random perturbations on th einitial conditions) data assimilation for reducing the errors. Specially important for cyclones, tropical storms, etc.\n",
    "- produce samples of initial uncertainties to initialize the ensamble.\n",
    "- Forecasting the weather from hours to seasons is an initial conditions problem: we need to accurately know the state of the Earth system at time t=+0h (the analysis) to make useful forecasts into the future.\n",
    "- To produce the analyses we use a data assimilation cycle where we blend short-range forecasts and new observations.\n",
    "- The fusion of forecast and observations is done at ECMWF with 4D-Var: 4D-Var adjusts the model forecast to better fit the new available observations both in space and time (4D).\n",
    "- In every analysis we use ~ 40 million new observations, the vast majority from satellites.\n",
    "- As both model and observations have errors, the analysis will also have errors (but smaller!).\n",
    "- We represent these uncertainties with ensemble data assimilation (EDA). This produces an ensemble of initial conditions which span the uncertainties of the analyses.\n",
    "## Similarities between Data Assimilation and Machine Learning\n",
    "- Deep Learning and 4D-Var are conceptually similar: minimize a cost (loss) function fusing together prior information and new observations.\n",
    "- run offline a database of a supercomputing thing (not in operation because it is costly) and train the NN.\n",
    "- Another option is to use analyses produced by a data assimilation system as a proxy for the true state and train the Neural Network (NN) to learn the model error from them.\n",
    "- wc-4DVar progressively learns a model error correction and applies it to subsequent background forecasts during the assimilation cycle\n",
    "- wc-4DVar is an online machine learning algorithm for model error estimation and correction!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d28439-a714-4d39-ae0c-26cda1cf7d8d",
   "metadata": {},
   "source": [
    "# Post-processing\n",
    "## concept and state of the art by Sebastian Lerch\n",
    "\n",
    "- ensemble forecast fail to accurately and reliably qunatify uncertainty. Thats where post-processing comes.\n",
    "- calibration: compatibility between forecast and observations -> verification range histogram.\n",
    "- proper scoring rules (continuous ranked meteorogical score)\n",
    "- sharpness\n",
    "- observations typical are out of the ensamble forecast. postprocessing is necessary to improve them. Take the ensamble forcast and produce a probabilistic forecast.  Ensamble model output statistics (EMOS).\n",
    "- another methods exist for post processing\n",
    "  - bayesian model averaging\n",
    "  - member by member approaches\n",
    "  - quantile regression\n",
    "- software for postprocessing: R package crch and scoringRules\n",
    "\n",
    "## postprocessing with ML\n",
    "- moder, highdimensional, large data sets\n",
    "- gradient boosting for EMOS\n",
    "- quantile regression forest\n",
    "- incorporate spatial and temploral infromation into model building and stimation (CNN, downscaling?)\n",
    "- incorporates previos knowledges\n",
    "- flexible models and complex response distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb761692-3d71-4e7c-9578-37df2b46e688",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
